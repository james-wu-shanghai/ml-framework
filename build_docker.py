"""
Dockeræ„å»ºå’Œéƒ¨ç½²è„šæœ¬

è‡ªåŠ¨åŒ–æ„å»ºML Frameworkçš„Dockeré•œåƒ
"""

import subprocess
import sys
import os
import argparse
from pathlib import Path


def run_command(command, description, check=True):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print(f"\nğŸ”§ {description}...")
    print(f"æ‰§è¡Œå‘½ä»¤: {command}")
    
    try:
        result = subprocess.run(command, shell=True, check=check, 
                              capture_output=True, text=True)
        if result.stdout:
            print(result.stdout)
        if result.stderr and result.returncode != 0:
            print(f"é”™è¯¯: {result.stderr}")
        print(f"âœ… {description} å®Œæˆ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {description} å¤±è´¥: {e}")
        if e.stderr:
            print(f"é”™è¯¯è¯¦æƒ…: {e.stderr}")
        return False


def check_docker():
    """æ£€æŸ¥Dockerç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥Dockerç¯å¢ƒ...")
    
    # æ£€æŸ¥Dockeræ˜¯å¦å®‰è£…
    if not run_command("docker --version", "æ£€æŸ¥Dockerç‰ˆæœ¬", check=False):
        print("âŒ Dockeræœªå®‰è£…æˆ–ä¸å¯ç”¨")
        return False
    
    # æ£€æŸ¥Docker Compose
    if not run_command("docker-compose --version", "æ£€æŸ¥Docker Composeç‰ˆæœ¬", check=False):
        print("âš ï¸ Docker Composeæœªå®‰è£…ï¼Œå°†ä½¿ç”¨dockerå‘½ä»¤")
    
    # æ£€æŸ¥NVIDIA Dockeræ”¯æŒ
    if not run_command("docker run --rm --gpus all nvidia/cuda:12.4-base-ubuntu22.04 nvidia-smi", 
                      "æ£€æŸ¥NVIDIA Dockeræ”¯æŒ", check=False):
        print("âš ï¸ NVIDIA Dockeræ”¯æŒä¸å¯ç”¨ï¼Œå°†æ„å»ºCPUç‰ˆæœ¬")
        return False
    
    return True


def build_image(image_type="full", tag="latest"):
    """æ„å»ºDockeré•œåƒ"""
    print(f"\nğŸ“¦ æ„å»º{image_type}ç‰ˆæœ¬é•œåƒ...")
    
    dockerfile = "Dockerfile" if image_type == "full" else "Dockerfile.prod"
    image_name = f"ml-framework:{tag}"
    
    build_command = f"docker build -f {dockerfile} -t {image_name} ."
    
    if run_command(build_command, f"æ„å»º{image_name}é•œåƒ"):
        print(f"âœ… é•œåƒ {image_name} æ„å»ºæˆåŠŸ")
        return True
    else:
        print(f"âŒ é•œåƒ {image_name} æ„å»ºå¤±è´¥")
        return False


def test_image(image_name="ml-framework:latest"):
    """æµ‹è¯•Dockeré•œåƒ"""
    print(f"\nğŸ§ª æµ‹è¯•é•œåƒ {image_name}...")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    test_commands = [
        f"docker run --rm {image_name} python -c 'import ml_framework; print(\"ML Frameworkå¯¼å…¥æˆåŠŸ\")'",
        f"docker run --rm --gpus all {image_name} python -c 'import torch; print(f\"PyTorch CUDA: {{torch.cuda.is_available()}}\")'",
        f"docker run --rm --gpus all {image_name} python -c 'import tensorflow as tf; print(f\"TensorFlow GPU: {{len(tf.config.list_physical_devices(\"GPU\"))}}\")'",
    ]
    
    all_passed = True
    for i, cmd in enumerate(test_commands, 1):
        if not run_command(cmd, f"æµ‹è¯• {i}/{len(test_commands)}", check=False):
            all_passed = False
    
    if all_passed:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return False


def deploy_services():
    """éƒ¨ç½²æœåŠ¡"""
    print("\nğŸš€ éƒ¨ç½²æœåŠ¡...")
    
    if not Path("docker-compose.yml").exists():
        print("âŒ docker-compose.ymlæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # å¯åŠ¨æœåŠ¡
    deploy_commands = [
        "docker-compose down",  # åœæ­¢ç°æœ‰æœåŠ¡
        "docker-compose build",  # æ„å»ºé•œåƒ
        "docker-compose up -d jupyter api streamlit",  # å¯åŠ¨æ ¸å¿ƒæœåŠ¡
    ]
    
    for cmd in deploy_commands:
        if not run_command(cmd, f"æ‰§è¡Œ: {cmd}"):
            return False
    
    print("\nâœ… æœåŠ¡éƒ¨ç½²å®Œæˆ")
    print("ğŸ“ å¯ç”¨æœåŠ¡:")
    print("  - Jupyter Notebook: http://localhost:8888")
    print("  - FastAPI: http://localhost:8000")
    print("  - Streamlit: http://localhost:8501")
    
    return True


def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
    print("\nğŸ“– Dockeré•œåƒä½¿ç”¨è¯´æ˜")
    print("=" * 50)
    print("åŸºæœ¬ä½¿ç”¨:")
    print("  # äº¤äº’å¼è¿è¡Œ")
    print("  docker run -it --gpus all -v $(pwd)/data:/app/data ml-framework:latest shell")
    print()
    print("  # å¯åŠ¨Jupyter")
    print("  docker run -d --gpus all -p 8888:8888 ml-framework:latest jupyter")
    print()
    print("  # å¯åŠ¨APIæœåŠ¡")
    print("  docker run -d --gpus all -p 8000:8000 ml-framework:latest api")
    print()
    print("  # è®­ç»ƒæ¨¡å‹")
    print("  docker run --gpus all -v $(pwd)/data:/app/data ml-framework:latest train --data data/my_data.csv --target target")
    print()
    print("ä½¿ç”¨Docker Compose:")
    print("  # å¯åŠ¨æ‰€æœ‰æœåŠ¡")
    print("  docker-compose up -d")
    print()
    print("  # æŸ¥çœ‹æœåŠ¡çŠ¶æ€")
    print("  docker-compose ps")
    print()
    print("  # æŸ¥çœ‹æ—¥å¿—")
    print("  docker-compose logs -f")
    print()
    print("  # åœæ­¢æœåŠ¡")
    print("  docker-compose down")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ML Framework Dockeræ„å»ºè„šæœ¬")
    parser.add_argument("--type", choices=["full", "prod"], default="full",
                       help="é•œåƒç±»å‹ (full: å®Œæ•´ç‰ˆ, prod: ç”Ÿäº§ç‰ˆ)")
    parser.add_argument("--tag", default="latest", help="é•œåƒæ ‡ç­¾")
    parser.add_argument("--no-test", action="store_true", help="è·³è¿‡æµ‹è¯•")
    parser.add_argument("--deploy", action="store_true", help="éƒ¨ç½²æœåŠ¡")
    parser.add_argument("--usage", action="store_true", help="æ˜¾ç¤ºä½¿ç”¨è¯´æ˜")
    
    args = parser.parse_args()
    
    if args.usage:
        show_usage()
        return 0
    
    print("ğŸ³ ML Framework Dockeræ„å»ºå·¥å…·")
    print("=" * 40)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_docker():
        print("âŒ Dockerç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return 1
    
    # æ„å»ºé•œåƒ
    image_name = f"ml-framework:{args.tag}"
    if not build_image(args.type, args.tag):
        print("âŒ é•œåƒæ„å»ºå¤±è´¥")
        return 1
    
    # æµ‹è¯•é•œåƒ
    if not args.no_test:
        if not test_image(image_name):
            print("âš ï¸ é•œåƒæµ‹è¯•æœ‰é—®é¢˜ï¼Œä½†æ„å»ºæˆåŠŸ")
    
    # éƒ¨ç½²æœåŠ¡
    if args.deploy:
        if not deploy_services():
            print("âŒ æœåŠ¡éƒ¨ç½²å¤±è´¥")
            return 1
    
    print("\nğŸ‰ Dockeræ„å»ºå®Œæˆ!")
    show_usage()
    
    return 0


if __name__ == "__main__":
    sys.exit(main())