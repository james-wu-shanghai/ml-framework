# ML Framework ä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

ML Framework æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„Pythonæœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œæä¾›ä»æ•°æ®å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´å·¥ä½œæµç¨‹ã€‚å®ƒé›†æˆäº†sklearnã€pytorchç­‰ä¸»æµMLåº“ï¼Œæ”¯æŒåˆ†ç±»ã€å›å½’ã€èšç±»ç­‰å¤šç§ä»»åŠ¡ã€‚

## ğŸš€ å®‰è£…å’Œè®¾ç½®

### 1. ç¯å¢ƒè¦æ±‚

- Python 3.8+
- æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ

### 2. å®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†é¡¹ç›®ï¼ˆå¦‚æœä»Gitï¼‰
git clone <repository-url>
cd ml-framework

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. å®‰è£…ä¾èµ–
python install_dependencies.py
# æˆ–è€…
pip install -r requirements.txt

# 4. æµ‹è¯•å®‰è£…
python test_framework.py
```

## ğŸ“š åŸºç¡€ä½¿ç”¨

### 1. æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼

```python
from ml_framework import quick_start

# ä¸€è¡Œä»£ç å®Œæˆæ•´ä¸ªMLæµç¨‹
framework = quick_start(
    data_path='your_data.csv',
    target_column='target',
    task_type='classification'  # æˆ– 'regression', 'clustering'
)

# è®­ç»ƒå’Œè¯„ä¼°
framework.preprocess_data()
framework.select_model('random_forest')
framework.train()
results = framework.evaluate()

print(f"å‡†ç¡®ç‡: {results['accuracy']:.4f}")
```

### 2. å®Œæ•´çš„å·¥ä½œæµç¨‹

```python
from ml_framework import MLFramework

# 1. åˆå§‹åŒ–æ¡†æ¶
framework = MLFramework(config_path='configs/default_config.yaml')

# 2. åŠ è½½æ•°æ®
framework.load_data('data.csv', target_column='target')

# 3. è®¾ç½®ä»»åŠ¡ç±»å‹
framework.set_task_type('classification')

# 4. æ•°æ®é¢„å¤„ç†
framework.preprocess_data(
    scale_features=True,
    handle_missing='mean',
    encode_categorical=True
)

# 5. é€‰æ‹©å’Œé…ç½®æ¨¡å‹
framework.select_model('random_forest', 
                      n_estimators=100, 
                      max_depth=10)

# 6. è®­ç»ƒæ¨¡å‹
framework.train(validation_split=0.2)

# 7. è¯„ä¼°æ¨¡å‹
results = framework.evaluate()

# 8. å¯è§†åŒ–ç»“æœ
framework.visualize_results()

# 9. ä¿å­˜æ¨¡å‹
framework.save_model('models/my_model.joblib')
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰é…ç½®

```python
# ä½¿ç”¨é…ç½®æ–‡ä»¶
framework = MLFramework(config_path='my_config.yaml')

# è¿è¡Œæ—¶ä¿®æ”¹é…ç½®
framework.config.set('data.batch_size', 64)
framework.config.set('training.epochs', 200)

# ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
framework.config.from_env('ML_FRAMEWORK_')
```

### 2. æ¨¡å‹æ¯”è¾ƒ

```python
models = ['random_forest', 'logistic_regression', 'svm']
results = {}

for model_name in models:
    # åˆ›å»ºç‹¬ç«‹çš„æ¡†æ¶å®ä¾‹
    temp_framework = MLFramework()
    temp_framework.load_data('data.csv', target_column='target')
    temp_framework.set_task_type('classification')
    temp_framework.preprocess_data()
    
    temp_framework.select_model(model_name)
    temp_framework.train()
    
    results[model_name] = temp_framework.evaluate()

# æ¯”è¾ƒç»“æœ
comparison_df = framework.evaluator.compare_models(results)
best_model = framework.evaluator.get_best_model(results)
print(f"æœ€ä½³æ¨¡å‹: {best_model}")
```

### 3. è‡ªåŠ¨æœºå™¨å­¦ä¹ 

```python
# è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹å’Œå‚æ•°
results = framework.auto_ml(
    data_path='data.csv',
    target_column='target',
    task_type='classification'
)
```

### 4. å®éªŒè·Ÿè¸ª

```python
# å¼€å§‹å®éªŒè·Ÿè¸ª
framework.metrics_tracker.start_run('experiment_1')

# è®°å½•å‚æ•°
framework.metrics_tracker.log_parameters({
    'model': 'random_forest',
    'n_estimators': 100,
    'max_depth': 10
})

# è®­ç»ƒå’Œè¯„ä¼°
framework.train()
results = framework.evaluate()

# è®°å½•æŒ‡æ ‡
framework.metrics_tracker.log_metrics(results)

# ç»“æŸå®éªŒ
framework.metrics_tracker.end_run()
```

## ğŸ¨ å¯è§†åŒ–åŠŸèƒ½

```python
# æ•°æ®å¯è§†åŒ–
framework.visualizer.plot_data_distribution(data)
framework.visualizer.plot_correlation_matrix(data)

# æ¨¡å‹æ€§èƒ½å¯è§†åŒ–
framework.visualize_results()

# ç‰¹å¾é‡è¦æ€§
framework.visualizer.plot_feature_importance(
    model, feature_names, top_k=20
)

# åˆ›å»ºä»ªè¡¨æ¿
framework.visualizer.create_dashboard(data, results)
```

## ğŸ’» å‘½ä»¤è¡Œå·¥å…·

### 1. åˆå§‹åŒ–é¡¹ç›®

```bash
python -m ml_framework.cli init
```

### 2. è®­ç»ƒæ¨¡å‹

```bash
python -m ml_framework.cli train \
    --data data.csv \
    --target target_column \
    --model random_forest \
    --task-type classification \
    --output models/my_model.joblib
```

### 3. è¯„ä¼°æ¨¡å‹

```bash
python -m ml_framework.cli evaluate \
    --model models/my_model.joblib \
    --data test_data.csv \
    --target target_column
```

### 4. é¢„æµ‹

```bash
python -m ml_framework.cli predict \
    --model models/my_model.joblib \
    --data new_data.csv \
    --output predictions.csv
```

### 5. è‡ªåŠ¨ML

```bash
python -m ml_framework.cli auto \
    --data data.csv \
    --target target_column \
    --task-type classification
```

## ğŸ“‹ æ”¯æŒçš„æ•°æ®æ ¼å¼

- **CSV**: `.csv`
- **Excel**: `.xlsx`, `.xls`
- **JSON**: `.json`
- **Parquet**: `.parquet`
- **Pickle**: `.pkl`, `.pickle`

```python
# åŠ è½½ä¸åŒæ ¼å¼çš„æ•°æ®
framework.load_data('data.csv', target_column='target')
framework.load_data('data.xlsx', target_column='target')
framework.load_data('data.json', target_column='target')
```

## ğŸ¤– æ”¯æŒçš„æ¨¡å‹

### åˆ†ç±»æ¨¡å‹
- `random_forest`: éšæœºæ£®æ—
- `logistic_regression`: é€»è¾‘å›å½’
- `svm`: æ”¯æŒå‘é‡æœº
- `decision_tree`: å†³ç­–æ ‘

### å›å½’æ¨¡å‹
- `random_forest`: éšæœºæ£®æ—å›å½’
- `linear_regression`: çº¿æ€§å›å½’
- `svm`: æ”¯æŒå‘é‡å›å½’
- `decision_tree`: å†³ç­–æ ‘å›å½’

### èšç±»æ¨¡å‹
- `kmeans`: Kå‡å€¼èšç±»

```python
# ä½¿ç”¨ä¸åŒæ¨¡å‹
framework.select_model('random_forest', n_estimators=100)
framework.select_model('logistic_regression', max_iter=1000)
framework.select_model('svm', kernel='rbf', C=1.0)
```

## âš ï¸ å¸¸è§é—®é¢˜

### 1. å†…å­˜ä¸è¶³

```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
framework.config.set('data.batch_size', 16)

# ä½¿ç”¨ç‰¹å¾é€‰æ‹©
framework.config.set('preprocessing.feature_selection_k', 20)
```

### 2. è®­ç»ƒé€Ÿåº¦æ…¢

```python
# å‡å°‘æ¨¡å‹å¤æ‚åº¦
framework.select_model('random_forest', n_estimators=50)

# ä½¿ç”¨å¹¶è¡Œå¤„ç†
framework.select_model('random_forest', n_jobs=-1)
```

### 3. ç²¾åº¦ä¸é«˜

```python
# å°è¯•ä¸åŒçš„é¢„å¤„ç†
framework.preprocess_data(scaler='robust', handle_missing='knn')

# å°è¯•ä¸åŒçš„æ¨¡å‹
framework.select_model('svm', kernel='rbf', C=10)

# ä½¿ç”¨äº¤å‰éªŒè¯
framework.config.set('training.cross_validation.enabled', True)
```

## ğŸ”§ æ‰©å±•å¼€å‘

### 1. æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹

```python
from ml_framework.models.base import BaseModel

class MyModel(BaseModel):
    def fit(self, X, y, **kwargs):
        # å®ç°è®­ç»ƒé€»è¾‘
        pass
    
    def predict(self, X):
        # å®ç°é¢„æµ‹é€»è¾‘
        pass

# æ³¨å†Œæ¨¡å‹
framework.model_registry.models['classification']['my_model'] = MyModel
```

### 2. æ·»åŠ è‡ªå®šä¹‰é¢„å¤„ç†

```python
def custom_preprocessing(data):
    # è‡ªå®šä¹‰é¢„å¤„ç†é€»è¾‘
    return processed_data

# åº”ç”¨è‡ªå®šä¹‰é¢„å¤„ç†
framework.data_processor.add_custom_step(custom_preprocessing)
```

### 3. æ·»åŠ è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡

```python
def custom_metric(y_true, y_pred):
    # è®¡ç®—è‡ªå®šä¹‰æŒ‡æ ‡
    return score

# ä½¿ç”¨è‡ªå®šä¹‰æŒ‡æ ‡
results = framework.evaluate(custom_metrics={'my_metric': custom_metric})
```

## ğŸ“Š æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
- æ£€æŸ¥æ•°æ®è´¨é‡å’Œä¸€è‡´æ€§
- å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
- è¿›è¡Œç‰¹å¾å·¥ç¨‹
- ç¡®ä¿æ•°æ®åˆ†å¸ƒåˆç†

### 2. æ¨¡å‹é€‰æ‹©
- ä»ç®€å•æ¨¡å‹å¼€å§‹
- ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°
- æ¯”è¾ƒå¤šä¸ªæ¨¡å‹
- è€ƒè™‘æ¨¡å‹çš„å¯è§£é‡Šæ€§

### 3. å®éªŒç®¡ç†
- è®°å½•æ‰€æœ‰å®éªŒå‚æ•°
- ä¿å­˜æ¨¡å‹å’Œç»“æœ
- ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶
- å»ºç«‹è¯„ä¼°åŸºçº¿

### 4. æ€§èƒ½ä¼˜åŒ–
- ç›‘æ§èµ„æºä½¿ç”¨
- ä½¿ç”¨å¹¶è¡Œå¤„ç†
- ä¼˜åŒ–æ•°æ®åŠ è½½
- åˆç†é€‰æ‹©æ‰¹æ¬¡å¤§å°

è¿™ä¸ªä½¿ç”¨æŒ‡å—æ¶µç›–äº†ML Frameworkçš„ä¸»è¦åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•ã€‚æ¡†æ¶è®¾è®¡éµå¾ªäº†æ¨¡å—åŒ–ã€å¯æ‰©å±•å’Œæ˜“ç”¨çš„åŸåˆ™ï¼Œé€‚åˆå„ç§æœºå™¨å­¦ä¹ é¡¹ç›®çš„éœ€æ±‚ã€‚